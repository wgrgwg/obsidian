- 자연어 처리(Natural Language Processing, NLP)
- 크게 두가지 유형의 문제가 연구됨
	1. **NLP 기반 서비스를 위한 실용 평가**
		- 서비스를 위한 실제성능 측정에 초점
		- 자동 번역, 개체명 인식, 감성 분석
	2. **기계의 언어 이해 능력을 파악**
		- AI모델이 언어를 얼마나 잘 이해하나?
		- 언어의 복잡성과 다양성 처리 능력
		- entailment, 의미론적 유사성, 문맥적 의미 분석, 객관식 문제 풀기
		- **기반 모델로서의 잠재력 평가**

## Application 관점의 NLP
#### NLP 기반의 서비스, 해결할 문제
1. **형태소 분석기**
	- 텍스트를 개별 형태소로 분리, 기능 식별
	- 품사 태깅, 구문 속성 분석
	- **자연어 데이터를 의미적으로 분석**

2. **구문 분석기**
	- 문장 구조 분석, 문법적 관계 파악
	- 문장을 여러 단위로 분절

3. **개체명 인식기**
	- 텍스트에서 인명, 지명, 기관명 등 특정 정보를 식별, 분류
	- 정보 추출, 문서 요약

4. **번역기**
	- 언어 변환
	- 광범위한 문법 지식 + 대규모 어휘 DB 필요
	- 이미지 -> 텍스트 번역

5. **문법 및 철자 교정기**
	- 문법적 오류, 철자 오류 수정
	- 음성 인식, 채팅 메시지 정규화, 교정에 활용

6. **감성 분석기**
	- 텍스트에서 감정의 극성(긍정, 부정, 중립) 판단
	- 시장 조사, 고객 서비스 개선

7. **음성 인식 시스템**
	- 음성을 텍스트로 변환
	- 가상 비서, 챗 서비스

8. **챗봇**
	- 질문에 자동으로 응답
	- 고객 서비스 자동화, 대화형 마케팅

9. **추천 시스템**
	- 과거 이력, 프로파일 데이터 분석
	- 개인화된 서비스 추천

10. **주제 분류기**
	- 텍스트 전체를 분석, 주제를 분류
	- 텍스트의 주요 카테고리를 분류

### N21 모델링
- N개의 token을 입력 받아 하나의 결과를 도출함
	- 주제 분류기 : `텍스트` -> `단일 카테고리`
	- 감성 분석기 : `텍스트` -> `극성`
	- 추천 시스템 : `사용자 데이터` -> `하나의 추천 목록`

###### 손실 함수
- **Cross-Entropy Loss**
	- 분류 문제에 주로 사용
	- 모델 예측 확률 분포와 실제 레이블의 분포 사이의 차이를 측정

###### 평가 메트릭
- **정확도(Accuracy)**
	- 모델이 얼마나 정확하게 각 카테고리를 예측하는지
- **F1 Score**
	- 데이터의 클래스가 불균형할 때 유용
	- 정밀도와 재현율의 조화 평균을 측정

### N2N 모델링
- 각 입력 단위가 각각 독립적인 출력을 만듦
	- 형태소 분석기 : `텍스트 N개 토큰` -> `품사 태깅`
	- 문법, 절차 교정기 : `오류를 개별적으로 식별`
	- 개체명 인식기 : `각 토큰 -> 개채명 매핑`

###### 손실 함수
 - **Cross-Entropy Loss**
	- 모든 토큰에 대해서 손실 계산 -> 평균
	- 예측과 실제의 분포 차이를 측정

###### 평가 메트릭
- **Precision**
	- 모델 예측 결과 중 실제 일치 비율 측정
	- 개체명 인식에서 중요
- **Recall**
	- 실제 필요 결과 중 모델이 얼마나 잡았는지
	- 중요 정보를 놓치지 않았는지 평가
- **F1 Score**
	- 균형 잡힌 성능을 보이는지
	- Precision과 Recall의 조화 평균을 측정
	- 두 메트릭의  균형을 평가

### N2M 모델링
- 하나의 입력으로 여러 개의 출력 생성
	- 구문 분석기 : `문장 하나 -> 구조를 분해`
	- 번역기 : `하나의 문장 -> 다른 언어 문장`
	- 문법 및 철자 교정기 : `여러 오류 검출 -> 다수의 수정 제안`
	- 챗봇 : `질문 token N개` -> `응답 M개`

- **굳이 encoder-decoder 기반 기술 안써도 가능**
	- **Decoder only**로 N2M문제 푸는 GPT

###### 손실 함수
- **Cross-Entropy Loss**
	- 예측과 실제의 분포 차이를 측정
- **Perplexity**
	- 주로 언어 모델 성능 평가에 사용
	- 모델이 데이터를 얼마나 잘 예측하는지
	- **낮을수록 좋음**
- **Connectionist Temporal Classification (CTC) Loss**
	- 음성 인식, 필기 인식에서 사용
	- 입-출력의 **시간적 정렬이 불확실**
	- 요소의 입-출 매핑의 확률을 최대화
- **Contrastive Loss**
	- 질문 응답 등 쌍 구성 데이터에 사용
	- 맞는 답변 - 잘못 답변 사이의 마진을 최대화 

###### 평가 메트릭
- **BLEU Score**
	- 번역 품질 측정에 사용
	- n-gram의 오버랩을 비교
- **ROUGE Score**
	- 요약 태스크에 사용
	- 생성-참조 요약 유사도 측정
	- `로그-N`, `로그-L`등 다양한 형태로 사용
- **Edit Distance**
	- 출력-목표 시퀀스 사이의 수정 필요 횟수 측정
	- 문법, 절차 교정기에 굿
	- 시퀀스의 유사도 **정량적 평가**

### 결론
- 자연어 처리 문제를 N21, N2N, N2M 등 패턴으로 모델링
- 손실 함수, 평가 방식도 살펴보기